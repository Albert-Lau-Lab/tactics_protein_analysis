{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an ML Model That Finds Cryptic Pockets Within MD Trajectories.\n",
    "The training dataset consits of crystal structures from the extended Cryptosite database.  There are several structures for each protein in the database.  One structures is \"holo\"; i.e. it has a cryptic pocket.  The other structures are \"apo\"; i.e. they (hopefully) don't have the pocket.  The data is meant to mimic an MD trajectory in which some frames have the pocket and others don't.\n",
    "\n",
    "It is assumed that the only holo structure is the one found the Cryptosite database.  This assumption isn't always true; i.e. some of the (supposedly) \"apo\" structures may have cryptic pockets that are partially or fully open.  This introduces error into the database; the database is expected to be useful despite the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the dataset.\n",
    "The notebook cell below creates the dataframe `df_train` that stores training data for ML.  It contains a line for each residue of each protein in the extended database.  Each line contains the following:\n",
    "* Info about the protein and residue.\n",
    "* Info about the \"crypto_apo\" protein.  This is the apo protein from the Cryptosite database with the same sequence as the protein.\n",
    "* Info about the holo protein from the Cryptosite database.\n",
    "* Misc. features for ML, which are added later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from align import align_res_nums\n",
    "from get_concavity_score import get_concavity_score\n",
    "\n",
    "\n",
    "# Delete old output\n",
    "ali_output_dir = \"apo_holo_alignments\"\n",
    "if os.path.isdir(ali_output_dir):\n",
    "    shutil.rmtree(ali_output_dir)\n",
    "os.mkdir(ali_output_dir)\n",
    "\n",
    "conc_output_dir = \"train_set_conc\"\n",
    "if os.path.isdir(conc_output_dir):\n",
    "    shutil.rmtree(conc_output_dir)\n",
    "os.mkdir(conc_output_dir)\n",
    "\n",
    "\n",
    "# Initialize the training set data as a list.  Start by adding the data from the apo and holo proteins\n",
    "# in the original cryptosite database.  This is necessary because later parts of the code require that\n",
    "# cryptosite's apo and holo structures are present.\n",
    "\n",
    "# Later, the code will convert the list to a DataFrame.  This is faster than iteratively creating a DataFrame.\n",
    "train_set_as_list = []\n",
    "df_cryptosite_orig = pd.read_csv(\"../generate_training_database/gen_crypto_database/cryptosite_database.csv\")\n",
    "for index, row in df_cryptosite_orig.iterrows():\n",
    "    # Add cryptosite holo.\n",
    "    train_set_as_list.append([row[\"holo_pdb_id\"].lower(), row[\"holo_chain\"], row[\"holo_resnum\"],\n",
    "                              row[\"holo_pdb_id\"].lower(), row[\"holo_chain\"], row[\"holo_resnum\"],\n",
    "                              row[\"apo_pdb_id\"].lower(), row[\"apo_chain\"], row[\"apo_resnum\"],\n",
    "                              row[\"is_cryptic\"]])\n",
    "    # Add cryptosite apo.  By definition is_cryptic=False for all apo residues.\n",
    "    train_set_as_list.append([row[\"apo_pdb_id\"].lower(), row[\"apo_chain\"], row[\"apo_resnum\"],\n",
    "                              row[\"holo_pdb_id\"].lower(), row[\"holo_chain\"], row[\"holo_resnum\"],\n",
    "                              row[\"apo_pdb_id\"].lower(), row[\"apo_chain\"], row[\"apo_resnum\"],\n",
    "                              False])\n",
    "\n",
    "# Find which chain of each holo PDB is in the database.\n",
    "cryptosite_db_list_loc = (\"../generate_training_database/gen_crypto_database/pdbs_and_ligands.csv\")\n",
    "with open(cryptosite_db_list_loc, \"r\") as cryptosite_db_list_file:\n",
    "    cryptosite_db_list_lines = cryptosite_db_list_file.readlines()\n",
    "dict_holo_chains = {}\n",
    "for line in cryptosite_db_list_lines[1:]:\n",
    "    holo_pdb_id = line[7:11].lower()\n",
    "    holo_chain_id = line[12]\n",
    "    dict_holo_chains[holo_pdb_id] = holo_chain_id\n",
    "dict_crypto_apo_chains = {}\n",
    "for line in cryptosite_db_list_lines[1:]:\n",
    "    apo_pdb_id = line[0:4].lower()\n",
    "    apo_chain_id = line[5]\n",
    "    dict_crypto_apo_chains[apo_pdb_id] = apo_chain_id\n",
    "    \n",
    "dict_crypto_apo_to_holo = {}\n",
    "for line in cryptosite_db_list_lines[1:]:\n",
    "    crypto_apo_pdb_id = line[0:4].lower()\n",
    "    crypto_apo_chain_id = line[5]\n",
    "    crypto_apo_pdb_and_chain = crypto_apo_pdb_id + \":\" + crypto_apo_chain_id\n",
    "    holo_pdb_id = line[7:11].lower()\n",
    "    holo_chain_id = line[12]\n",
    "    dict_holo_to_crypto_apo[holo_pdb_id] = crypto_apo_pdb_and_chain\n",
    "\n",
    "num_passed = 0 # Useful for estimating how fast the code is running\n",
    "#for apo_list_loc in sorted(glob.glob(\"extended_db/*good*\"))[0:10]:\n",
    "for apo_list_loc in sorted(glob.glob(\"extended_db/*good*\")):\n",
    "    crypto_apo_pdb_id = apo_list_loc[12:16]\n",
    "    crypto_apo_chain_id = dict_crypto_apo_chains[crypto_apo_pdb_id]\n",
    "    holo_pdb_id = dict_crypto_apo_to_holo[crypto_apo_pdb_id]\n",
    "    holo_chain_id = dict_holo_chains[holo_pdb_id]\n",
    "    holo_pdb_loc = (\"../generate_training_database/gen_crypto_database/holo_structures/%s.pdb\" %(holo_pdb_id))\n",
    "    # 1AFQ.C and 2CGA.B don't show up in each other's sequence identity clusters.  I suspect that this is because\n",
    "    # part of 2CGA.B corresponds to 1AFQ.B; this is a result of 1AFQ being divided into more chains than 2CGA.\n",
    "    # Regardless of if this is a correct explanation, the code must look at the cryptosite database to get the\n",
    "    # crypto_apo because of this issue.\n",
    "    crypto_apo_pdb_loc = (\"../generate_training_database/gen_crypto_database/\"\n",
    "                          \"apo_structures/%s.pdb\" %(crypto_apo_pdb_id))\n",
    "    with open(apo_list_loc, \"r\") as apo_list_opened:\n",
    "        apo_list_lines = apo_list_opened.readlines()\n",
    "    for line in apo_list_lines[1:min(len(apo_list_lines), 51)]: # Skip the header, and read only 50 lines.\n",
    "        apo_pdb_id = line[0:4]\n",
    "        apo_pdb_loc = (\"/home/devans61/Desktop/ml_on_traj/extended_db/\"\n",
    "                       \"%s_download_pdbs/%s.pdb\" %(crypto_apo_pdb_id, apo_pdb_id))\n",
    "        apo_chain_id = line[5]\n",
    "        print(\"num_passed\", num_passed, \"args\", apo_pdb_loc, apo_chain_id, holo_pdb_loc, holo_chain_id)\n",
    "        apo_holo_dict = align_res_nums(apo_pdb_loc, apo_chain_id, holo_pdb_loc, holo_chain_id)\n",
    "        apo_holo_dict_loc = \"%s/apo_%s%s_holo_%s%s.json\" %(ali_output_dir, apo_pdb_id, apo_chain_id,\n",
    "                                                           holo_pdb_id, holo_chain_id)\n",
    "        print(apo_pdb_id, holo_pdb_id)\n",
    "        with open(apo_holo_dict_loc, \"w\") as apo_holo_dict_file:\n",
    "            json.dump(apo_holo_dict, apo_holo_dict_file)\n",
    "            \n",
    "        apo_crypto_apo_dict = align_res_nums(apo_pdb_loc, apo_chain_id, crypto_apo_pdb_loc, crypto_apo_chain_id)\n",
    "        apo_crypto_apo_dict_loc = \"%s/apo_%s%s_crypto_apo_%s%s.json\" %(ali_output_dir, apo_pdb_id, apo_chain_id,\n",
    "                                                                       crypto_apo_pdb_id, crypto_apo_chain_id)\n",
    "        print(apo_pdb_id, crypto_apo_pdb_id)\n",
    "        with open(apo_crypto_apo_dict_loc, \"w\") as apo_crypto_apo_dict_file:\n",
    "            json.dump(apo_crypto_apo_dict, apo_crypto_apo_dict_file)\n",
    "\n",
    "        for apo_resnum, holo_resnum in apo_holo_dict.items():\n",
    "            crypto_apo_resnum = apo_crypto_apo_dict[apo_resnum]\n",
    "            train_set_as_list.append([apo_pdb_id, apo_chain_id, apo_resnum,\n",
    "                                      holo_pdb_id, holo_chain_id, holo_resnum, \n",
    "                                      crypto_apo_pdb_id, crypto_apo_chain_id, crypto_apo_resnum,\n",
    "                                      False])\n",
    "    num_passed += 1\n",
    "df_train = pd.DataFrame(train_set_as_list, columns=[\"prot_id\", \"chain_id\", \"resnum\",\n",
    "                                                    \"holo_prot_id\", \"holo_chain_id\", \"holo_resnum\",\n",
    "                                                    \"crypto_apo_prot_id\",\"crypto_apo_chain_id\", \"crypto_apo_resnum\",\n",
    "                                                    \"is_site\"])\n",
    "df_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
